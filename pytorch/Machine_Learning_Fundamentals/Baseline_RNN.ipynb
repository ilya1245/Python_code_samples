{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qssAVJoBlyfF"
   },
   "source": [
    "# Fundamentals of Machine Learning, Fall 2021, Final Project\n",
    "\n",
    "## Stock Closing Price Prediction\n",
    "\n",
    "1. Download ```final_project.pdf```, ```Kaggle & Colab Guide.pptx```, and ```utils.py``` from i-campus.\n",
    "2. Go to [Kaggle competition page](https://www.kaggle.com/c/2021mlfinal), join Kaggle & competition, and download dataset.\n",
    "3. Following guide slides, upload ```utils.py```.\n",
    "4. Mount Google Drive.\n",
    "5. Implement your own model and predict on test dates.\n",
    "6. Download and submit ```submission.csv``` to Kaggle.\n",
    "7. Write a report on your project and submit on i-campus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOvOEV5rmCYu"
   },
   "source": [
    "# INITIAL PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hRqwRAFkl4-r"
   },
   "outputs": [],
   "source": [
    "# INITIAL PACKAGES\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import load_data, run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZUsyNe95i_o"
   },
   "source": [
    "## Mount Google Drive\n",
    "\n",
    "Assmue you made ```final_project``` directory on the root,\n",
    "and data files are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MDM_tdygDwZm",
    "outputId": "fb402568-65d1-4cc2-b3b6-6e708667ecc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qRW-lZn5qQ8",
    "outputId": "74d98565-5d61-4909-fe77-633a848f9ffd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submission.csv',\n",
       " 'valid_id_answer.csv',\n",
       " 'test_id.csv',\n",
       " 'train_id_answer.csv',\n",
       " 'test_input.npy',\n",
       " 'valid_input.npy',\n",
       " 'train_input.npy',\n",
       " 'utils.py']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdrive_root = '/content/gdrive/My Drive'\n",
    "data_path = os.path.join(gdrive_root, 'final_project')\n",
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UyVzURjPKEbn"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data, test_input = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R31c7TpoKFcb",
    "outputId": "6757aa1a-0d16-4091-97ed-adedd03549d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train id answer:\n",
      "            id    answer\n",
      "0  Z1HpN8DdqD -0.897532\n",
      "1  4kZUPHdZCm  0.222965\n",
      "2  4B9Zruxygn  3.562945\n",
      "3  8BhHCriaH2  2.666667\n",
      "4  mkYyKwYdek -2.083333\n",
      "train input shape: (739, 142, 60, 11)\n",
      "\n",
      "valid id answer:\n",
      "            id    answer\n",
      "0  XqAfjiZoin  2.627939\n",
      "1  P8fIDWGztk  1.814882\n",
      "2  qSWi7pDeyq -7.017544\n",
      "3  JZq9kbg8gY  1.449275\n",
      "4  dOiCHAt5wv -5.991736\n",
      "valid input shape: (248, 142, 60, 11)\n",
      "\n",
      "test id:\n",
      "            id\n",
      "0  Nqx4Oqo6eJ\n",
      "1  RKI4KKxRdT\n",
      "2  U6MPA99ktR\n",
      "3  ztP24qyofv\n",
      "4  TjGmwz9Z7T\n",
      "test input shape: (245, 142, 60, 11)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'train id answer:\\n {train_data[0].head()}')\n",
    "print(f'train input shape: {train_data[1].shape}\\n')\n",
    "\n",
    "print(f'valid id answer:\\n {valid_data[0].head()}')\n",
    "print(f'valid input shape: {valid_data[1].shape}\\n')\n",
    "\n",
    "print(f'test id:\\n {test_input[0].head()}')\n",
    "print(f'test input shape: {test_input[1].shape}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jyZX7csmRzj"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQTSxSQdmVoD"
   },
   "source": [
    "# SHOW YOUR WORK\n",
    "From here, import packages you need as long as they are permitted. <br>\n",
    "Fill ```train_and_predict``` function with your codes. <br>\n",
    "If you want, you can implement your own classes or functions within \"SHOW YOUR WOKR\" block. <br>\n",
    "The rest of work is ours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvtsgWZAIAbD"
   },
   "outputs": [],
   "source": [
    "# set random seed for reproducibility\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.random.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "set_random_seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4feaJ6yVmZPX"
   },
   "outputs": [],
   "source": [
    "# IMPORT PACKAGES YOU NEED\n",
    "\n",
    "import torch.nn as nn\n",
    "from time import time\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cl5hOI1mnP2B"
   },
   "outputs": [],
   "source": [
    "# YOUR OWN CLASSES OR FUNCTIONS\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.layers = nn.Sequential(nn.Linear(self.input_dim, self.input_dim), nn.Tanh(), nn.RNN(input_size=self.input_dim, hidden_size=self.hidden_dim, num_layers=1, batch_first=True))\n",
    "        self.logit_layer = nn.Linear(self.hidden_dim, 1)\n",
    "  \n",
    "    def forward(self, x, index=None):\n",
    "        hidden_x, hn_x = self.layers(x)\n",
    "\n",
    "        output = self.logit_layer(hn_x).squeeze()\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HYzEGLBcH_av"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hAadQh8Bmbwx"
   },
   "outputs": [],
   "source": [
    "def train_and_predict(train_data, valid_data, test_data):\n",
    "    \"\"\"Train a model and return prediction on test input.\n",
    "\n",
    "    Given train and valid data, build your model and optimize.\n",
    "    Then, return predictions on test_input.\n",
    "\n",
    "    You can import packages you want inside 'EDIT HERE' as long as they are permitted.\n",
    "    (See document for the list of possible packages)\n",
    "\n",
    "    arguments:\n",
    "        train_data: tuple of (pandas.DataFrame, np.array).\n",
    "        - 0: pandas.DataFrame with columns ['id', 'answer']\n",
    "          'id' contains unique id assigned to each timestamp.\n",
    "          'answer' contains closing price ratio corresponding to its timestamp.\n",
    "        - 1: train input in np.array of (# of train timestamps, 1 + # of stocks, # of previous dates to be input, # of features)\n",
    "\n",
    "        valid_data: tuple of (pandas.DataFrame, np.array).\n",
    "        - 0: pandas.DataFrame with columns ['id', 'answer']\n",
    "          'id' contains unique id assigned to each timestamp.\n",
    "          'answer' contains closing price ratio corresponding to its timestamp.\n",
    "        - 1: valid input in np.array of (# of valid timestamps, 1 + # of stocks, # of previous dates to be input, # of features)\n",
    "\n",
    "        test_data: tuple of (pandas.DataFrame, np.array).\n",
    "        - 0: pandas.DataFrame with columns ['id']\n",
    "          'id' contains unique id assigned to each timestamp.\n",
    "        - 1: test input in np.array of (# of test timestamps, 1 + # of stocks, # of previous dates to be input, # of features)\n",
    "    \n",
    "    returns:\n",
    "        pandas.DataFrame, predictions on test input with columns ['id', 'answer'].\n",
    "        'id' should contain unique id assigned to test input. \n",
    "        'answer' should contain prediction on the test input correspond to its id\n",
    "\n",
    "    \"\"\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    LEARNING_RATE = 0.01\n",
    "    BATCH_SIZE = 256\n",
    "    TEST_BATCH_SIZE = 1024\n",
    "    NUM_EPOCHS = 200\n",
    "    PATIENCE = 10\n",
    "    ENDURE = 15\n",
    "\n",
    "    # Example code for DecisionTreeRegressor:\n",
    "    train_id_answer, train_input = train_data\n",
    "    valid_id_answer, valid_input = valid_data\n",
    "    test_id, test_input = test_data\n",
    "\n",
    "    num_train = len(train_input)\n",
    "    num_valid = len(valid_input)\n",
    "    num_test = len(test_input)\n",
    "\n",
    "    # Separate index\n",
    "    index_train = train_input[:, 0]\n",
    "    x_train = train_input[:, 1:]\n",
    "    y_train = train_id_answer['answer'].values\n",
    "\n",
    "    index_valid = valid_input[:, 0]\n",
    "    x_valid = valid_input[:, 1:]\n",
    "    y_valid = valid_id_answer['answer'].values\n",
    "\n",
    "    index_test = test_input[:, 0]\n",
    "    x_test = test_input[:, 1:]\n",
    "\n",
    "    # Use last 60 days to train, 10 days to valid\n",
    "    x_train = x_train[-60:]\n",
    "    y_train = y_train[-60*x_train.shape[1]:]\n",
    "\n",
    "    x_valid = x_valid[-10:]\n",
    "    y_valid = y_valid[-10*x_valid.shape[1]:]\n",
    "\n",
    "    # Use previous 3 days to predict\n",
    "    x_train = x_train[:, :, -3:]\n",
    "    x_valid = x_valid[:, :, -3:]\n",
    "    x_test = x_test[:, :, -3:]\n",
    "\n",
    "    # Fit data shape for model\n",
    "    x_train_shape = x_train.shape\n",
    "    x_train = x_train.reshape(x_train_shape[0] * x_train_shape[1], x_train_shape[2], -1)\n",
    "\n",
    "    x_valid_shape = x_valid.shape\n",
    "    x_valid = x_valid.reshape(x_valid_shape[0] * x_valid_shape[1], x_valid_shape[2], -1)\n",
    "\n",
    "    x_test_shape = x_test.shape\n",
    "    x_test = x_test.reshape(x_test_shape[0] * x_test_shape[1], x_test_shape[2], -1)\n",
    "\n",
    "    # Convert data into torch.Tensor\n",
    "    x_train = torch.FloatTensor(x_train)\n",
    "    y_train = torch.FloatTensor(y_train)\n",
    "\n",
    "    x_valid = torch.FloatTensor(x_valid)\n",
    "    y_valid = torch.FloatTensor(y_valid)\n",
    "\n",
    "    x_test = torch.FloatTensor(x_test)\n",
    "\n",
    "    # Build torch dataset, dataloader\n",
    "    print(x_train.shape, y_train.shape)\n",
    "    print(x_valid.shape, y_valid.shape)\n",
    "    print(x_test.shape)\n",
    "    train_dataset = TensorDataset(x_train, y_train)\n",
    "    valid_dataset = TensorDataset(x_valid, y_valid)\n",
    "    test_dataset = TensorDataset(x_test)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE)\n",
    "\n",
    "    # Build RNN model\n",
    "    model = MyModel(x_train.shape[-1], 100).to(device)\n",
    "\n",
    "    # Optimizer and loss function\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_fn = nn.L1Loss()\n",
    "    \n",
    "    # Train model\n",
    "    mean_train_losses = []\n",
    "    mean_valid_losses = []\n",
    "    valid_mae_list = []\n",
    "    best_mae = 99999\n",
    "\n",
    "    train_s = time()\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        epoch_s = time()\n",
    "        model.train()\n",
    "        \n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        for i, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "        model.eval()\n",
    "        \n",
    "        val_pred = []\n",
    "        val_gt = []\n",
    "        # Disable gradient calculation for memory, computation efficiency\n",
    "        with torch.no_grad():\n",
    "            for i, (inputs, targets) in enumerate(valid_loader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                \n",
    "                valid_losses.append(loss.item())\n",
    "                val_pred += outputs.detach().cpu().numpy().tolist()\n",
    "                val_gt += targets.detach().cpu().numpy().tolist()\n",
    "                \n",
    "        mean_train_losses.append(np.mean(train_losses))\n",
    "        mean_valid_losses.append(np.mean(valid_losses))\n",
    "\n",
    "        epoch_elapsed = time() - epoch_s\n",
    "        \n",
    "        valid_mae = mean_absolute_error(val_gt, val_pred)\n",
    "        valid_mae_list.append(valid_mae)\n",
    "        print('epoch: {}, train loss: {:.4f}, valid loss: {:.4f}, valid mae: {:.4f}, elapsed: {:.4f}'\\\n",
    "            .format(epoch, np.mean(train_losses), np.mean(valid_losses), valid_mae, epoch_elapsed))\n",
    "        \n",
    "        if best_mae > valid_mae:\n",
    "            print('Best Accuracy updated (%.4f => %.4f)' % (best_mae, valid_mae))\n",
    "            best_mae = valid_mae\n",
    "            best_epoch = epoch\n",
    "            ENDURE = 0\n",
    "            # Save best model\n",
    "            torch.save(model.state_dict(), 'best_rnn.p')\n",
    "        else:\n",
    "            ENDURE += 1\n",
    "            if ENDURE >= PATIENCE:\n",
    "                print('Early stop triggered...!')\n",
    "                break\n",
    "    train_elapsed = time() - train_s\n",
    "\n",
    "    print('Training Finished...!!')\n",
    "    print('Time: %.4f' % train_elapsed)\n",
    "    print('Best Valid acc : %.4f at epoch %d' % (best_mae, best_epoch))\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load('best_rnn.p'))\n",
    "    model.eval()\n",
    "\n",
    "    # Make prediction on test data\n",
    "    test_preds = []\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, ) in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            if device == 'cuda':\n",
    "                test_preds += outputs.detach().cpu().numpy().tolist()\n",
    "            else:\n",
    "                test_preds += outputs.detach().numpy().tolist()\n",
    "    \n",
    "    # Make prediction data frame\n",
    "    test_id['answer'] = test_preds\n",
    "    pred = test_id.loc[:, ['id', 'answer']]\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uz7Fho1vmdRa"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSTAchdzmfB6"
   },
   "source": [
    "# YOUR WORK IS DONE!\n",
    "Do not touch any line below. <br>\n",
    "```run``` function will grap your prediction and make ```submission.csv```. <br>\n",
    "Take it and submit to Kaggle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TDXCvXCimjAc",
    "outputId": "be1d42a4-62ba-4ce5-d023-2f91f3e15ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8460, 3, 11]) torch.Size([8460])\n",
      "torch.Size([1410, 3, 11]) torch.Size([1410])\n",
      "torch.Size([34545, 3, 11])\n",
      "epoch: 1, train loss: 1.5276, valid loss: 1.8992, valid mae: 1.8772, elapsed: 0.1647\n",
      "Best Accuracy updated (99999.0000 => 1.8772)\n",
      "epoch: 2, train loss: 1.5231, valid loss: 1.9053, valid mae: 1.8836, elapsed: 0.1834\n",
      "epoch: 3, train loss: 1.5224, valid loss: 1.9089, valid mae: 1.8874, elapsed: 0.1374\n",
      "epoch: 4, train loss: 1.5221, valid loss: 1.9114, valid mae: 1.8900, elapsed: 0.1395\n",
      "epoch: 5, train loss: 1.5218, valid loss: 1.9131, valid mae: 1.8917, elapsed: 0.1523\n",
      "epoch: 6, train loss: 1.5218, valid loss: 1.9121, valid mae: 1.8908, elapsed: 0.1471\n",
      "epoch: 7, train loss: 1.5214, valid loss: 1.9116, valid mae: 1.8903, elapsed: 0.1377\n",
      "epoch: 8, train loss: 1.5211, valid loss: 1.9112, valid mae: 1.8900, elapsed: 0.1571\n",
      "epoch: 9, train loss: 1.5209, valid loss: 1.9110, valid mae: 1.8898, elapsed: 0.1407\n",
      "epoch: 10, train loss: 1.5207, valid loss: 1.9108, valid mae: 1.8896, elapsed: 0.1420\n",
      "epoch: 11, train loss: 1.5204, valid loss: 1.9108, valid mae: 1.8896, elapsed: 0.1424\n",
      "Early stop triggered...!\n",
      "Training Finished...!!\n",
      "Time: 1.6586\n",
      "Best Valid acc : 1.8772 at epoch 1\n",
      "\n",
      "Save Completed...!!\n"
     ]
    }
   ],
   "source": [
    "run(train_and_predict, train_data, valid_data, test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BLvMabmGzmwN"
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Baseline_RNN.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
